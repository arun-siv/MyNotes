{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c366a1cc",
   "metadata": {},
   "source": [
    "# Smarter pandas\n",
    "\n",
    "## A Seminar by ‘Don’t Use This Code’\n",
    "\n",
    "![Logo: Don’t Use This Code, LLC](logo-small.png)\n",
    "\n",
    "**Presenter**: James Powell <james@dutc.io>\n",
    "\n",
    "<div style=\"display: flex; justify-content: center; font-size: 2em; width: auto; padding: .25em 5em .25em 5em;\">\n",
    "    <p style=\"text-align: center\">\n",
    "        Join us on <a href=\"https://discord.gg/ZhJPKYSfNp\">Discord (https://discord.gg/ZhJPKYSfNp)</a> for discussion and guidance!\n",
    "    </p>\n",
    "</div>\n",
    "\n",
    "## Contents\n",
    "\n",
    "* [A Seminar by ‘Don’t Use This Code’](#a-seminar-by-‘don’t-use-this-code’)\n",
    "* [Book a Class!](#book-a-class!)\n",
    "* [Notes](#notes)\n",
    "* [About](#about)\n",
    "  * [Don’t Use This Code; Training & Consulting](#don’t-use-this-code;-training-&-consulting)\n",
    "\n",
    "## Book a Class!\n",
    "\n",
    "<big><big>Book a class or training for your team!</big></big>\n",
    "\n",
    "Please reach out to us at [learning@dutc.io](mailto:learning@dutc.io) if are\n",
    "interested in bringing this material, or any of our other material, to your\n",
    "team.\n",
    "\n",
    "We have courses on topics such as:\n",
    "- intro Python\n",
    "- expert Python\n",
    "- data engineering with Python\n",
    "- data science and scientific computing with `numpy`, `pandas`, and `xarray`\n",
    "\n",
    "If you reach out to us, we can also provide a printable copy of the notes,\n",
    "cleaned-up and in .pdf format, as well as a professionally edited video\n",
    "recording of this presentation.\n",
    "\n",
    "## Notes\n",
    "\n",
    "<div style=\"display: flex; justify-content: center; font-size: 2em; width: auto; padding: .25em 5em .25em 5em;\">\n",
    "    <p style=\"text-align: center\">\n",
    "        <a href=\"materials/2023-06-16-pandas-data.zip\">Data Files (2023-06-16-pandas-data.zip)</a>\n",
    "    </p>\n",
    "</div>\n",
    "\n",
    "### Context\n",
    "\n",
    "> Star Trader is a 1974 video game and an early example of the space trading\n",
    "> genre. The game involves players moving from star to star on a map of the\n",
    "> galaxy, buying and selling quantities of six types of merchandise in a\n",
    "> competition to make the most money. The game was developed by Dave Kaufman\n",
    "> for computers in 1973, and its BASIC source code was printed in the January\n",
    "> 1974 issue of the People’s Computer Company Newsletter. It was reprinted in\n",
    "> the 1977 book What to Do After You Hit Return. The game was the inspiration\n",
    "> for the multiplayer Trade Wars series, beginning in 1984, and is thought to\n",
    "> be the antecedent to much of the space trading genre.\n",
    "\n",
    "— [*Star Trader* on Wikipedia.org](https://en.wikipedia.org/wiki/Star_Trader)\n",
    "\n",
    "![Star Trader, 1974](https://upload.wikimedia.org/wikipedia/en/d/d2/Star_Trader_1974_screenshot.png)\n",
    "### Data Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b315c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's take a look!\n"
     ]
    }
   ],
   "source": [
    "print(\"Let's take a look!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d935c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_dir = WindowsPath('data')\n",
      "p = WindowsPath('data/inventory.csv')\n",
      "p = WindowsPath('data/locations.csv')\n",
      "p = WindowsPath('data/market.csv')\n",
      "p = WindowsPath('data/marks.csv')\n",
      "p = WindowsPath('data/messages.csv')\n",
      "p = WindowsPath('data/real-market.csv')\n",
      "p = WindowsPath('data/real-trades.csv')\n",
      "p = WindowsPath('data/trades.csv')\n",
      "p = WindowsPath('data/trips.csv')\n",
      "p = WindowsPath('data/inventory.pkl')\n",
      "p = WindowsPath('data/locations.pkl')\n",
      "p = WindowsPath('data/market.pkl')\n",
      "p = WindowsPath('data/marks.pkl')\n",
      "p = WindowsPath('data/messages.pkl')\n",
      "p = WindowsPath('data/real-market.pkl')\n",
      "p = WindowsPath('data/real-trades.pkl')\n",
      "p = WindowsPath('data/trades.pkl')\n",
      "p = WindowsPath('data/trips.pkl')\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "data_dir = Path('data')\n",
    "\n",
    "print(f'{data_dir = }')\n",
    "\n",
    "for p in sorted(data_dir.iterdir()):\n",
    "    if p.suffix == '.csv':\n",
    "        print(f'{p = }')\n",
    "\n",
    "for p in sorted(data_dir.iterdir()):\n",
    "    if p.suffix == '.pkl':\n",
    "        print(f'{p = }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bdea508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_dir = WindowsPath('data')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from pandas import read_pickle\n",
    "data_dir = Path('data')\n",
    "\n",
    "print(f'{data_dir = }')\n",
    "inventory = read_pickle(data_dir / 'inventory.pkl')\n",
    "locations = read_pickle(data_dir / 'locations.pkl')\n",
    "market = read_pickle(data_dir / 'market.pkl')\n",
    "marks = read_pickle(data_dir / 'marks.pkl')\n",
    "messages = read_pickle(data_dir / 'messages.pkl')\n",
    "trades = read_pickle(data_dir / 'trades.pkl')\n",
    "trips = read_pickle(data_dir / 'trips.pkl')\n",
    "\n",
    "real_market = read_pickle(data_dir / 'real-market.pkl')\n",
    "real_trades = read_pickle(data_dir / 'real-trades.pkl')\n",
    "\n",
    "print(\n",
    "    # inventory.sample(5).sort_index(),\n",
    "    # locations.sample(5).sort_index(),\n",
    "    # market.sample(5).sort_index(),\n",
    "    # marks.sample(5).sort_index(),\n",
    "    # messages.sample(5).sort_index(),\n",
    "    # trades.sample(5).sort_index(),\n",
    "    # trips.sample(5).sort_index(),\n",
    "\n",
    "    # real_market.sample(5).sort_index(),\n",
    "    # real_trades.sample(5).sort_index(),\n",
    "    sep='\\n{}\\n'.format('\\N{box drawings light horizontal}' * 40),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f27244e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from pandas import read_pickle, read_csv\n",
    "data_dir = Path('data')\n",
    "\n",
    "print(\n",
    "    sep='\\n{}\\n'.format('\\N{box drawings light horizontal}' * 40),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f44252",
   "metadata": {},
   "source": [
    "### Background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9507439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's take a look!\n"
     ]
    }
   ],
   "source": [
    "print(\"Let's take a look!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb9d25a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from pandas import read_pickle, read_csv\n",
    "data_dir = Path('data')\n",
    "\n",
    "print(\n",
    "    sep='\\n{}\\n'.format('\\N{box drawings light horizontal}' * 40),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cb5bad",
   "metadata": {},
   "source": [
    "#### What is a “restricted computation domain”?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a51dd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import default_rng\n",
    "rng = default_rng(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da435bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 4 6]\n",
      "────────────────────────────────────────\n",
      "[1, 2, 3, 1, 2, 3]\n",
      "────────────────────────────────────────\n",
      "[3 6 9]\n",
      "────────────────────────────────────────\n",
      "[1, 2, 3, 1, 2, 3, 1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "\n",
    "xs = array([1, 2, 3])\n",
    "ys = [1, 2, 3]\n",
    "\n",
    "print(\n",
    "    xs + xs, # adds element-wise (mathematical; vector addition)\n",
    "    ys + ys, # adds structure-wise (structural; concatenation)\n",
    "    xs * 3,  # vector/scalar multiplication\n",
    "    ys * 3,  # repetition\n",
    "    sep='\\n{}\\n'.format('\\N{box drawings light horizontal}' * 40)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2068d22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "# nested list\n",
    "xs = [\n",
    "    [1, 2, 3],\n",
    "    [1, 2, 3, 4],\n",
    "    [1, 2, 3],\n",
    "]\n",
    "\n",
    "# matrix\n",
    "xs = array([\n",
    "    [1, 2, 3],\n",
    "    [1, 2, 3],\n",
    "    [1, 2, 3],\n",
    "])\n",
    "\n",
    "print(xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350cca51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy: dynamic shape, static size (cannot resize in-place)\n",
    "# python, list: dynamic size, static shape (always linear)\n",
    "\n",
    "xs = [1, 2, 3]\n",
    "xs.append(4)\n",
    "xs.append(5)\n",
    "\n",
    "# for x in xs:\n",
    "#     print(x)\n",
    "\n",
    "from numpy import array\n",
    "\n",
    "xs = array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12])\n",
    "print(xs.reshape(2, 2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4157df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy.ndarray: interpreted view of raw memory\n",
    "from numpy import array\n",
    "\n",
    "xs = array([1, 2, 3, 4, 5, 6, 7, 8])\n",
    "# xs.shape = 2, 4\n",
    "xs.dtype = 'int8'\n",
    "print(\n",
    "    xs,\n",
    "    f'{xs.dtype   = }',\n",
    "    f'{xs.shape   = }',\n",
    "    f'{xs.size    = }',\n",
    "    f'{xs.strides = }',\n",
    "    f'{xs.__array_interface__[\"data\"][0] = :#_x}',\n",
    "    sep='\\n',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56249e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python: dynamic, human-friendly\n",
    "#   “programme structuring”\n",
    "# numpy/pandas: restrictive, machine-friendly\n",
    "#   “computation”\n",
    "from time import perf_counter, sleep\n",
    "from contextlib import contextmanager\n",
    "\n",
    "@contextmanager\n",
    "def timed(msg):\n",
    "    before = perf_counter()\n",
    "    yield\n",
    "    after = perf_counter()\n",
    "    print(f'{msg:<48} \\N{mathematical bold capital delta}t: {after - before:.6f}s')\n",
    "\n",
    "# with timed('take a short nap'):\n",
    "#     sleep(1)\n",
    "\n",
    "from numpy.random import default_rng\n",
    "from random import Random\n",
    "from numpy import dot as np_dot\n",
    "py_dot = lambda xs, ys: sum(x*y for x, y in zip(xs, ys))\n",
    "\n",
    "rng = default_rng(0)\n",
    "rnd = Random(0)\n",
    "\n",
    "sz = 100_000\n",
    "\n",
    "with timed('py create'):\n",
    "    py_xs = [rnd.randint(-1_000, +1_000) for _ in range(sz)]\n",
    "    py_ys = [rnd.randint(-1_000, +1_000) for _ in range(sz)]\n",
    "\n",
    "with timed('np create'):\n",
    "    np_xs = rng.integers(-1_000, +1_000, size=sz)\n",
    "    np_ys = rng.integers(-1_000, +1_000, size=sz)\n",
    "\n",
    "with timed('py dot'):\n",
    "    py_dot(py_xs, py_ys)\n",
    "\n",
    "with timed('np dot'):\n",
    "    np_dot(np_xs, np_ys)\n",
    "\n",
    "with timed('np dot on py data'):\n",
    "    np_dot(py_xs, py_ys)\n",
    "with timed('py dot on np data'):\n",
    "    py_dot(np_xs, np_ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc55b2d8",
   "metadata": {},
   "source": [
    "#### What is “broadcasting”?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9142cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import default_rng\n",
    "rng = default_rng(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4685892b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "c1 = Counter('aaaaabbbccd')\n",
    "c2 = Counter('aaaaaaaabbccef')\n",
    "\n",
    "print(c1)\n",
    "print(c2)\n",
    "print(c1 + c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df32903",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import default_rng\n",
    "from numpy import broadcast_to\n",
    "\n",
    "rng = default_rng(0)\n",
    "\n",
    "xs = rng.normal(size=(5, 2, 1, 4)).round(2)\n",
    "ys = rng.normal(size=(5, 1, 3, 4)).round(2)\n",
    "# match the dimensions from right-to-left\n",
    "# - exact match\n",
    "# - one of them to be missing that dimension or dimension = 1\n",
    "\n",
    "shape = 5, 2, 3, 4\n",
    "print(\n",
    "    # xs,\n",
    "    # ys,\n",
    "    # xs + ys,\n",
    "    broadcast_to(xs, shape=shape),\n",
    "    broadcast_to(ys, shape=shape),\n",
    "    sep='\\n{}\\n'.format('\\N{box drawings light horizontal}' * 40),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800acfce",
   "metadata": {},
   "source": [
    "#### What is “index alignment”?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f6da9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import default_rng\n",
    "rng = default_rng(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a244ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import Series, date_range\n",
    "from numpy.random import default_rng\n",
    "rng = default_rng(0)\n",
    "\n",
    "s1 = Series(\n",
    "    rng.normal(size=9).round(2),\n",
    "    index=date_range('2020-01-01', periods=9, freq='2D'),\n",
    ")\n",
    "s2 = Series(\n",
    "    rng.normal(size=9).round(2),\n",
    "    index=date_range('2020-01-01', periods=9, freq='3D'),\n",
    ")\n",
    "\n",
    "print(\n",
    "    # s,\n",
    "    # s.iloc[1:5], # position-based access\n",
    "    # s.loc['2020-01-04':], # label-based access\n",
    "    # s.iloc[:5+1],\n",
    "    # s.loc[:'2020'],\n",
    "    s1,\n",
    "    s2,\n",
    "    s1 + s2,\n",
    "    # s1.add(s2, fill_value=1000),\n",
    "    sep='\\n{}\\n'.format('\\N{box drawings light horizontal}' * 40),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e50683",
   "metadata": {},
   "source": [
    "#### What is the fundamental structure?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69969e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import default_rng\n",
    "rng = default_rng(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c33f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import Series, DataFrame, date_range\n",
    "from numpy.random import default_rng\n",
    "rng = default_rng(0)\n",
    "\n",
    "s1 = Series(rng.normal(size=9).round(2), index=date_range('2020-01-01', periods=9))\n",
    "s2 = Series(rng.normal(size=9).round(2), index=date_range('2020-01-02', periods=9, freq='2D'))\n",
    "s3 = Series(rng.choice([True, False], size=9), index=date_range('2020-01-01', periods=9, freq='1D'))\n",
    "\n",
    "\n",
    "df = DataFrame({\n",
    "    'temp': s1,\n",
    "    'humd': s2,\n",
    "    'prec': s3,\n",
    "})\n",
    "df.index.name = 'datetime'\n",
    "df.columns.name = 'sensor'\n",
    "\n",
    "print(\n",
    "    # df.loc['2020-01-03'],\n",
    "    # df.loc[df.index.weekday == 0],\n",
    "    # df._data,\n",
    "    # df.index,\n",
    "    # df.columns,\n",
    "    # s1.index,\n",
    "    # s1.array,\n",
    "    # df.index,\n",
    "    df,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9caf5e5e",
   "metadata": {},
   "source": [
    "### Question: “Where’s everybody been?”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff603a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Let's take a look!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62a711d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date   player  star\n",
      "0  2020-01-01    Alice  Sink\n",
      "1  2020-01-01      Bob  Fate\n",
      "2  2020-01-01  Charlie  Ivan\n",
      "────────────────────────────────────────\n",
      "         date   player  star\n",
      "0  2020-01-01    Alice  Sink\n",
      "1  2020-01-01      Bob  Fate\n",
      "2  2020-01-01  Charlie  Ivan\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from pandas import read_csv\n",
    "data_dir = Path('data')\n",
    "\n",
    "locations = read_csv(data_dir / 'locations.csv')\n",
    "trips = read_csv(data_dir / 'trips.csv')\n",
    "\n",
    "print(\n",
    "    locations.head(3),\n",
    "    trips.head(3),\n",
    "    sep='\\n{}\\n'.format('\\N{box drawings light horizontal}' * 40),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43e6c28d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from pandas import read_csv\n",
    "data_dir = Path('data')\n",
    "\n",
    "# locations = read_csv(data_dir / 'locations.csv')\n",
    "trips = read_csv(data_dir / 'trips.csv', parse_dates=['date'])\n",
    "\n",
    "print(\n",
    "    # locations.head(3),\n",
    "    # trips.head(3),\n",
    "    # len(locations),\n",
    "    # len(trips),\n",
    "    # trips.dtypes,\n",
    "    # trips,\n",
    "    # trips['date'].dt.weekday,\n",
    "    sep='\\n{}\\n'.format('\\N{box drawings light horizontal}' * 40),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73d3a320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      2\n",
       "1      2\n",
       "2      2\n",
       "3      2\n",
       "4      3\n",
       "      ..\n",
       "488    4\n",
       "489    5\n",
       "490    5\n",
       "491    6\n",
       "492    6\n",
       "Name: date, Length: 493, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trips['date'].dt.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2976eafb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date        player \n",
      "2020-01-01  Alice      Sink\n",
      "            Bob        Fate\n",
      "            Charlie    Ivan\n",
      "            Dana       Stan\n",
      "2020-01-02  Bob        Quin\n",
      "                       ... \n",
      "2020-06-26  Charlie    Quin\n",
      "2020-06-27  Alice      Kirk\n",
      "            Bob         Sol\n",
      "2020-06-28  Alice      Hook\n",
      "            Charlie    Fate\n",
      "Name: star, Length: 493, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from pandas import read_csv, IndexSlice\n",
    "data_dir = Path('data')\n",
    "\n",
    "trips = (\n",
    "    read_csv(data_dir / 'trips.csv', parse_dates=['date'])\n",
    "    .set_index(['date', 'player'])\n",
    "    .squeeze(axis='columns')\n",
    ")\n",
    "\n",
    "print(\n",
    "    # trips.loc['2020-01-03':'2020-01-14'],\n",
    "    # trips.loc['2020-06-26', 'Charlie'],\n",
    "    # trips.loc[IndexSlice[:, 'Alice', :]],\n",
    "    # trips.loc[IndexSlice[:, ['Alice', 'Charlie'], :]],\n",
    "    trips,\n",
    "    sep='\\n{}\\n'.format('\\N{box drawings light horizontal}' * 40),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9422a2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(trips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "768c5f5b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many trips did Alice take?\n",
      "────────────────────────────────────────\n",
      "133\n",
      "────────────────────────────────────────\n",
      "How many trips were taken after March?\n",
      "────────────────────────────────────────\n",
      "331\n",
      "────────────────────────────────────────\n",
      "Where did Alice most frequently go (top 3)?\n",
      "────────────────────────────────────────\n",
      "York    21\n",
      "Gaol    16\n",
      "Sink    15\n",
      "Name: star, dtype: int64\n",
      "────────────────────────────────────────\n",
      "Where was Alice most frequently (top 3)?\n",
      "────────────────────────────────────────\n",
      "York    27\n",
      "Reef    21\n",
      "Sink    21\n",
      "Gaol    19\n",
      "Ivan    16\n",
      "Kirk    16\n",
      "Hook    15\n",
      "Sand    12\n",
      "Sol     11\n",
      "Boyd     9\n",
      "Stan     6\n",
      "Kris     4\n",
      "Quin     3\n",
      "Fate     0\n",
      "Task     0\n",
      "Name: star, dtype: int64\n",
      "────────────────────────────────────────\n",
      "star\n",
      "York    27\n",
      "Reef    21\n",
      "Sink    21\n",
      "Name: star, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from pandas import read_csv, IndexSlice, to_timedelta, date_range, MultiIndex\n",
    "data_dir = Path('data')\n",
    "\n",
    "trips = (\n",
    "    read_csv(data_dir / 'trips.csv', parse_dates=['date'])\n",
    "    .astype({\n",
    "        'player': 'category',\n",
    "        'star':   'category',\n",
    "    })\n",
    "    .set_index(['date', 'player'])\n",
    "    .squeeze(axis='columns')\n",
    ")\n",
    "\n",
    "print(\n",
    "    # trips,\n",
    "    'How many trips did Alice take?',\n",
    "    trips.loc[IndexSlice[:, 'Alice', :]].size,\n",
    "\n",
    "    'How many trips were taken after March?',\n",
    "    trips.loc[IndexSlice['2020-03':, :, :]].size,\n",
    "\n",
    "    'Where did Alice most frequently go (top 3)?',\n",
    "    trips.loc[IndexSlice[:, 'Alice', :]].value_counts().nlargest(3),\n",
    "\n",
    "    'Where was Alice most frequently (top 3)?',\n",
    "    # trips.loc[IndexSlice[:, 'Alice', :]].pipe(\n",
    "    #     lambda s: s.loc[\n",
    "    #         (gap := s.index.get_level_values('date').to_series().diff().idxmax()) + to_timedelta('-7d')\n",
    "    #         :\n",
    "    #         gap + to_timedelta('7d')\n",
    "    #     ]\n",
    "    # ),\n",
    "    trips.loc[IndexSlice[:, 'Alice', :]].pipe(\n",
    "        lambda s: s.reindex(date_range(s.index.min(), s.index.max())).ffill()\n",
    "    ).value_counts(),\n",
    "\n",
    "    # 'Where was each player most frequently (top 3)?',\n",
    "    trips.reindex(\n",
    "        MultiIndex.from_product([\n",
    "            date_range(\n",
    "                trips.index.get_level_values('date').min(),\n",
    "                trips.index.get_level_values('date').max(),\n",
    "                freq=trips.index.get_level_values('date').freq,\n",
    "                # name=trips.index.get_level_values('date').name,\n",
    "            ),\n",
    "            trips.index.get_level_values('player').unique(),\n",
    "        ], names=['date', 'player'])\n",
    "    )\n",
    "    .groupby('player').ffill()\n",
    "    .groupby('player').bfill()\n",
    "    .groupby('player').value_counts()\n",
    "    .groupby('player', group_keys=False).nlargest(3).loc['Alice']\n",
    "    ,\n",
    "    #.unstack('player').ffill().bfill().stack('player'),\n",
    "\n",
    "    # 2020-01-01 Alice       X\n",
    "    # 2020-01-02 Alice       X\n",
    "\n",
    "    # 2020-01-01 Bob         X\n",
    "    # 2020-01-02 Bob         NA\n",
    "\n",
    "    # 2020-01-01 Charlie     X\n",
    "    # 2020-01-02 Charlie     X\n",
    "\n",
    "    sep='\\n{}\\n'.format('\\N{box drawings light horizontal}' * 40),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "da45ef58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiIndex([('2020-01-01',   'Alice'),\n",
       "            ('2020-01-01',     'Bob'),\n",
       "            ('2020-01-01', 'Charlie'),\n",
       "            ('2020-01-01',    'Dana'),\n",
       "            ('2020-01-02',   'Alice'),\n",
       "            ('2020-01-02',     'Bob'),\n",
       "            ('2020-01-02', 'Charlie'),\n",
       "            ('2020-01-02',    'Dana'),\n",
       "            ('2020-01-03',   'Alice'),\n",
       "            ('2020-01-03',     'Bob'),\n",
       "            ...\n",
       "            ('2020-06-26', 'Charlie'),\n",
       "            ('2020-06-26',    'Dana'),\n",
       "            ('2020-06-27',   'Alice'),\n",
       "            ('2020-06-27',     'Bob'),\n",
       "            ('2020-06-27', 'Charlie'),\n",
       "            ('2020-06-27',    'Dana'),\n",
       "            ('2020-06-28',   'Alice'),\n",
       "            ('2020-06-28',     'Bob'),\n",
       "            ('2020-06-28', 'Charlie'),\n",
       "            ('2020-06-28',    'Dana')],\n",
       "           names=['date', 'player'], length=720)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "error uploading: HTTPSConnectionPool(host='api.segment.io', port=443): Max retries exceeded with url: /v1/batch (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000012115662AD0>: Failed to establish a new connection: [WinError 10051] A socket operation was attempted to an unreachable network'))\n"
     ]
    }
   ],
   "source": [
    " MultiIndex.from_product([\n",
    "            date_range(\n",
    "                trips.index.get_level_values('date').min(),\n",
    "                trips.index.get_level_values('date').max(),\n",
    "                freq=trips.index.get_level_values('date').freq,\n",
    "                # name=trips.index.get_level_values('date').name,\n",
    "            ),\n",
    "            trips.index.get_level_values('player').unique(),\n",
    "        ], names=['date', 'player'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14b23c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import perf_counter\n",
    "from contextlib import contextmanager\n",
    "\n",
    "@contextmanager\n",
    "def timed(msg):\n",
    "    before = perf_counter()\n",
    "    yield\n",
    "    after = perf_counter()\n",
    "    print(f'{msg:<48} \\N{mathematical bold capital delta}t: {after - before:.6f}s')\n",
    "\n",
    "from pandas import Series\n",
    "from numpy.random import default_rng\n",
    "from string import ascii_lowercase\n",
    "\n",
    "rng = default_rng(0)\n",
    "\n",
    "entities = rng.choice([*ascii_lowercase], size=(10, 4)).view('<U4').ravel()\n",
    "\n",
    "s1 = Series(\n",
    "    index=(idx := rng.choice(entities, size=100_000)),\n",
    "    data=rng.normal(size=len(idx)).round(2),\n",
    ")\n",
    "s2 = (\n",
    "    s1\n",
    "    .copy()\n",
    "    .pipe(lambda s:\n",
    "        s.set_axis(\n",
    "            s.index.astype('category'),\n",
    "            axis='index',\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\n",
    "    s1.head(3),\n",
    "    s2.head(3),\n",
    "    # s1.loc['wqnh'],\n",
    "    # s1.groupby(s1.index).mean(),\n",
    "    sep='\\n{}\\n'.format('\\N{box drawings light horizontal}' * 40),\n",
    ")\n",
    "\n",
    "with timed('Index'):\n",
    "    # s1.loc['wqnh']\n",
    "    # s1.index == 'wqnh'\n",
    "    # s1.groupby(s1.index).mean()\n",
    "    pass\n",
    "\n",
    "with timed('CategoricalIndex'):\n",
    "    # s2.loc['wqnh']\n",
    "    # s2.index == 'wqnh'\n",
    "    # s2.groupby(s2.index).mean()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5775a37",
   "metadata": {},
   "source": [
    "### Question: “What is it all worth?”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bef44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Let's take a look!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2bee54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from pandas import read_csv\n",
    "data_dir = Path('data')\n",
    "\n",
    "market = read_csv(data_dir / 'market.csv')\n",
    "inventory = read_csv(data_dir / 'inventory.csv')\n",
    "\n",
    "print(\n",
    "    market.head(3),\n",
    "    inventory.head(3),\n",
    "    sep='\\n{}\\n'.format('\\N{box drawings light horizontal}' * 40),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e1c114",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from pandas import read_csv\n",
    "data_dir = Path('data')\n",
    "\n",
    "market = (\n",
    "    read_csv(data_dir / 'market.csv', parse_dates=['date'])\n",
    "    .astype({\n",
    "        'star': 'category',\n",
    "        'asset': 'category',\n",
    "    })\n",
    "    .set_index(['date', 'star', 'asset'])\n",
    "    .rename_axis('direction', axis='columns')\n",
    "    # .stack()\n",
    ")\n",
    "inventory = (\n",
    "    read_csv(data_dir / 'inventory.csv')\n",
    "    .astype({\n",
    "        'player': 'category',\n",
    "        'asset':  market.index.get_level_values('asset').dtype,\n",
    "        'volume': 'Int64',\n",
    "    })\n",
    "    .set_index(['player', 'asset'])\n",
    "    .squeeze(axis='columns')\n",
    ")\n",
    "\n",
    "print(\n",
    "    # market.sample(3),\n",
    "    # inventory.sample(3),\n",
    "    # market.head(3),\n",
    "    # inventory.fillna(0),\n",
    "    # market.groupby(['asset']).mean(),\n",
    "    sep='\\n{}\\n'.format('\\N{box drawings light horizontal}' * 40),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8e7e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import Series, NA\n",
    "from numpy import nan\n",
    "\n",
    "s = Series([1.2, 3.4, 4.5, nan, 6.7])\n",
    "s = Series([1, 3, 4, 6, (2**53) + 1, (2**53) + 2, nan], dtype='Int64')#.dropna().astype(int)\n",
    "\n",
    "# IEEE-754 double precision (64-bit)\n",
    "# s e ... e f ... f\n",
    "# (s) * (1 + f) ^ (e)\n",
    "\n",
    "# 2's integer\n",
    "# ... ...\n",
    "\n",
    "print(\n",
    "    # float('inf'),\n",
    "    s._data,\n",
    "    # s._mask,\n",
    "    # dir(s),\n",
    "    sep='\\n{}\\n'.format('\\N{box drawings light horizontal}' * 40),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93926c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from pandas import read_csv\n",
    "data_dir = Path('data')\n",
    "\n",
    "market = (\n",
    "    read_csv(data_dir / 'market.csv', parse_dates=['date'])\n",
    "    .astype({\n",
    "        'star': 'category',\n",
    "        'asset': 'category',\n",
    "    })\n",
    "    .set_index(['date', 'star', 'asset'])\n",
    "    .rename_axis('direction', axis='columns')\n",
    "    # .stack()\n",
    ")\n",
    "inventory = (\n",
    "    read_csv(data_dir / 'inventory.csv')\n",
    "    .astype({\n",
    "        'player': 'category',\n",
    "        'asset':  market.index.get_level_values('asset').dtype,\n",
    "        'volume': 'Int64',\n",
    "    })\n",
    "    .set_index(['player', 'asset'])\n",
    "    .squeeze(axis='columns')\n",
    ")\n",
    "\n",
    "print(\n",
    "    'What is the spread for each asset for each location for each date?',\n",
    "    # market.head(3),\n",
    "    # (market['buy'] - market['sell']).head(3),\n",
    "    (market['buy'] - market['sell']),\n",
    "\n",
    "    'What is the average price for each asset/location/date?',\n",
    "    market.mean(axis='columns').rename('price'),\n",
    "\n",
    "    'What is Alice’s holdings worth on Jan 1 at Sol?',\n",
    "    (market.mean(axis='columns').rename('price').loc['2020-01-01', 'Sol'] * inventory.loc['Alice']),\n",
    "\n",
    "    'What are each user’s holdings worth?',\n",
    "    (market.mean(axis='columns').rename('price') * inventory),\n",
    "\n",
    "    'One what day was each player’s total holdings worth the most?',\n",
    "    (market.mean(axis='columns').rename('price') * inventory)\n",
    "    .groupby(['date', 'player', 'star']).sum()\n",
    "    .groupby(['date', 'player']).max()\n",
    "    .unstack('player').pipe(lambda s: s.idxmax())\n",
    "    # .unstack('player').idxmax()\n",
    "    # .groupby(['player']).idxmax()\n",
    "    ,\n",
    "\n",
    "    'What was the smoothed mean price for each asset?',\n",
    "    # market.mean(axis='columns').rolling(7, min_periods=1).mean(),\n",
    "    # market.mean(axis='columns').rolling('7D', min_periods=1).mean(),\n",
    "    # market\n",
    "    #     .mean(axis='columns')\n",
    "    #     .groupby(['star', 'asset']).filter(\n",
    "    #         lambda g: (g.loc[g > g.mean()]).all()\n",
    "    #     )\n",
    "    # ,#rolling(7, min_periods=1).mean(),\n",
    "    # market\n",
    "    #     .mean(axis='columns')\n",
    "    #     .groupby(['star', 'asset']).transform(\n",
    "    #         lambda g: g.droplevel(['star', 'asset']).rolling('7D', min_periods=1).mean().set_axis(g.index)\n",
    "    #     )\n",
    "    # ,\n",
    "    # market\n",
    "    #     .mean(axis='columns')\n",
    "    #     .groupby(['star', 'asset']).agg([\n",
    "    #         'max',\n",
    "    #         'min',\n",
    "    #         'mean',\n",
    "    #         'var',\n",
    "    #     ])\n",
    "    # ,\n",
    "    market\n",
    "        .mean(axis='columns')\n",
    "        .pipe(\n",
    "            lambda df:\n",
    "            df\n",
    "                .groupby(['star', 'asset'])\n",
    "                .pipe(\n",
    "                    lambda gb: (df - gb.mean()) / gb.std()\n",
    "                )\n",
    "        )\n",
    "        # .transform(\n",
    "        #     lambda g: (g - g.mean()) / g.std()\n",
    "        # )\n",
    "    ,\n",
    "\n",
    "\n",
    "    # market.mean(axis='columns').loc[\n",
    "    #     lambda s: s > 1000\n",
    "    # ],\n",
    "\n",
    "    # market.mean(axis='columns').groupby(['star', 'asset']).filter(\n",
    "    #     lambda g: sum(g > g.mean()) > (len(g) / 2)\n",
    "    # ),\n",
    "\n",
    "    # market.mean(axis='columns').groupby(['star', 'asset']).apply(\n",
    "    #     lambda g: g.loc[g > g.mean()]\n",
    "    # ),\n",
    "\n",
    "    market.mean(axis='columns').pipe(\n",
    "        lambda s:\n",
    "            s.loc[\n",
    "                s.groupby(['star', 'asset']).transform(\n",
    "                    lambda g: g > g.mean()\n",
    "                )\n",
    "            ]\n",
    "    ),\n",
    "\n",
    "    sep='\\n{}\\n'.format('\\N{box drawings light horizontal}' * 40),\n",
    ")\n",
    "\n",
    "# for _, g in market.mean(axis='columns').groupby(['star', 'asset']):\n",
    "#     print((g > g.mean()).values)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0361f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .groupby.max() # with a builtin\n",
    "\n",
    "# .groupby.filter(lambda g: g)\n",
    "\n",
    "# .groupby.agg(lambda g: g)\n",
    "#  input:  N rows of data that is grouped into M groups\n",
    "#  output: M rows of result indexed by the groups\n",
    "#  looks at one column at a time\n",
    "\n",
    "# .groupby.transform(lambda g: g)\n",
    "#  input:  N rows of data that is grouped into M groups\n",
    "#  ouput:  N rows of data indexed by whatever input was indexed\n",
    "#  looks at one column at a time (but has a fast path)\n",
    "\n",
    "# .groupby.apply(lambda g: g)\n",
    "#  input:  N rows of data that is grouped into M groups\n",
    "#  output: X rows of data indexed by whatever the result was of the UDF + group keys\n",
    "#  looks at all column at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4bb215",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import default_rng\n",
    "from pandas import DataFrame\n",
    "from string import ascii_lowercase\n",
    "from time import perf_counter\n",
    "from contextlib import contextmanager\n",
    "\n",
    "@contextmanager\n",
    "def timed(msg):\n",
    "    before = perf_counter()\n",
    "    yield\n",
    "    after = perf_counter()\n",
    "    print(f'{msg:<48}: \\N{mathematical bold capital delta}t: {after - before:.6f}s')\n",
    "\n",
    "rng = default_rng(0)\n",
    "\n",
    "df = DataFrame(\n",
    "    index=(idx := rng.choice(\n",
    "        rng.choice([*ascii_lowercase], size=(25_000, 8)).view('<U8').ravel(),\n",
    "        250_000,\n",
    "    )),\n",
    "    data={\n",
    "        'weight': rng.integers(1, 10, size=len(idx)),\n",
    "        'value':  rng.normal(size=len(idx)),\n",
    "    },\n",
    ").rename_axis(index='category', columns='measure')\n",
    "\n",
    "with timed('groupby.apply'):\n",
    "    df.groupby(df.index).apply(\n",
    "        lambda g: (g['weight'] * g['value']).sum() / g['weight'].sum()\n",
    "    )\n",
    "\n",
    "with timed('groupby.agg'):\n",
    "    df.assign(\n",
    "        weighted_values=lambda df: df['weight'] * df['value'],\n",
    "        grouped_total_weights=lambda df: df.groupby(df.index)['weight'].sum(),\n",
    "        grouped_total_weighted_values=lambda df: df.groupby(df.index)['weighted_values'].sum(),\n",
    "    ).pipe(\n",
    "        lambda df: df['grouped_total_weighted_values'] / df['grouped_total_weights']\n",
    "    )\n",
    "\n",
    "df = df.sample(frac=.01, random_state=rng).sort_index()\n",
    "print(\n",
    "    # df.groupby(df.index).apply(\n",
    "    #     lambda g: (g['weight'] * g['value']).sum() / g['weight'].sum()\n",
    "    # ),\n",
    "    # df.assign(\n",
    "    #     weighted_values=lambda df: df['weight'] * df['value'],\n",
    "    #     grouped_total_weights=lambda df: df.groupby(df.index)['weight'].sum(),\n",
    "    #     grouped_total_weighted_values=lambda df: df.groupby(df.index)['weighted_values'].sum(),\n",
    "    # ).pipe(\n",
    "    #     lambda df: df['grouped_total_weighted_values'] / df['grouped_total_weights']\n",
    "    # ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cfc67c",
   "metadata": {},
   "source": [
    "#### Rules of Index Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d325e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import Series, DataFrame, date_range\n",
    "from numpy.random import default_rng\n",
    "\n",
    "idx = date_range('2020-01-01', periods=30, name='date')\n",
    "rng = default_rng(0)\n",
    "s = Series(index=idx, data=rng.normal(size=len(idx)).round(2), name='value')\n",
    "df1 = DataFrame(\n",
    "    index=idx,\n",
    "    data={\n",
    "        'x': rng.normal(size=len(idx)).round(2),\n",
    "        'y': rng.normal(size=len(idx)).round(2),\n",
    "    },\n",
    ")\n",
    "df2 = DataFrame(\n",
    "    index=idx[10:],\n",
    "    data={\n",
    "        'y': rng.normal(size=len(idx[10:])).round(2),\n",
    "        'z': rng.normal(size=len(idx[10:])).round(2),\n",
    "    },\n",
    ")\n",
    "\n",
    "# DataFrame×DataFrame = align on .index .columns\n",
    "# Series×Series = align on .index\n",
    "# Series×DataFrame = align the .index of the Series against .columns of DataFrame\n",
    "\n",
    "print(\n",
    "    # df1.head(),\n",
    "    # df2.head(),\n",
    "    # df1 + df2,\n",
    "    # s.to_frame('x') + df1,\n",
    "    df1 * Series({'x': .5, 'y': 1.5}),\n",
    "    sep='\\n{}\\n'.format('\\N{box drawings light horizontal}' * 40),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc943a52",
   "metadata": {},
   "source": [
    "### Question: “What did you trade?”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00a38b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Let's take a look!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9a56ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from pandas import read_pickle\n",
    "data_dir = Path('data')\n",
    "\n",
    "market = read_pickle(data_dir / 'market.pkl')\n",
    "inventory = read_pickle(data_dir / 'inventory.pkl')\n",
    "trades = read_pickle(data_dir / 'trades.pkl')\n",
    "# marks = read_pickle(data_dir / 'marks.pkl')\n",
    "\n",
    "print(\n",
    "    market.head(3),\n",
    "    trades.head(3),\n",
    "    # marks.head(3),\n",
    "    sep='\\n{}\\n'.format('\\N{box drawings light horizontal}' * 40),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716ac6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from itertools import product\n",
    "from pandas import read_pickle, MultiIndex\n",
    "data_dir = Path('data')\n",
    "\n",
    "market = read_pickle(data_dir / 'market.pkl')\n",
    "inventory = read_pickle(data_dir / 'inventory.pkl')\n",
    "trades = read_pickle(data_dir / 'trades.pkl')\n",
    "locations = read_pickle(data_dir / 'locations.pkl')\n",
    "# marks = read_pickle(data_dir / 'marks.pkl')\n",
    "\n",
    "print(\n",
    "    'What are your positions at each point in time?',\n",
    "    # (inventory.fillna(0) + trades.groupby(['player', 'asset'])['volume'].cumsum())\n",
    "    # .groupby(['date', 'player', 'asset']).tail(1)\n",
    "    (\n",
    "        inventory.fillna(0)\n",
    "        +\n",
    "        trades['volume']\n",
    "            .groupby(['date', 'player', 'asset']).sum()\n",
    "            .groupby(['player', 'asset']).cumsum()\n",
    "    ).reorder_levels(['date', 'player', 'asset']).sort_index()\n",
    "    ,\n",
    "\n",
    "    # player asset date # trader\n",
    "    # date player asset # finance/management\n",
    "    # asset date player # risk/settlements\n",
    "\n",
    "    'How much are the holdings are worth at each point? (“market value”)',\n",
    "    df :=\n",
    "    trades.assign(\n",
    "        position=lambda df: (df['volume'].groupby(['player', 'asset']).cumsum() + inventory.fillna(0)).values,\n",
    "        direction=lambda df: (df['position'] > 0).map({True: 'buy', False: 'sell'}).astype(market.columns.dtype),\n",
    "        ldirection=lambda df: (df['position'] > 0).map({False: 'buy', True: 'sell'}).astype(market.columns.dtype),\n",
    "        star=lambda df: locations.loc[\n",
    "            MultiIndex.from_arrays([\n",
    "                df.index.get_level_values('date'),\n",
    "                df.index.get_level_values('player'),\n",
    "            ])\n",
    "        ].values,\n",
    "        asset_price=lambda df: market.stack('direction').loc[\n",
    "            MultiIndex.from_arrays([\n",
    "                [market.index.get_level_values('date').max()] * len(df), # end of period price\n",
    "                # df.index.get_level_values('date'), # same day price\n",
    "                df['star'],\n",
    "                df.index.get_level_values('asset'),\n",
    "                df['ldirection'],\n",
    "            ])\n",
    "        ].values,\n",
    "        market_value=lambda df: df['volume'] * df['asset_price'],\n",
    "        proceeds=lambda df: -df['volume'] * df['price'],\n",
    "        profit=lambda df: df['market_value'] + df['proceeds'],\n",
    "    )\n",
    "    # .drop(['star', 'asset_price', 'direction', 'ldirection'], axis='columns')\n",
    "    ,\n",
    "\n",
    "    # 'What is the best tradeable price?',\n",
    "    # market.stack('direction').pipe(\n",
    "    #     lambda s:\n",
    "    #         s.loc[\n",
    "    #             MultiIndex.from_tuples([\n",
    "    #                 (date, star, asset, direction)\n",
    "    #                 for star, (date, asset, direction) in\n",
    "    #                 product(\n",
    "    #                     market.index.get_level_values('star').unique(),\n",
    "    #                     zip(\n",
    "    #                         df.index.get_level_values('date'),\n",
    "    #                         df.index.get_level_values('asset'),\n",
    "    #                         df['ldirection'],\n",
    "    #                     ),\n",
    "    #                 )\n",
    "    #             ], names=s.index.names)\n",
    "    #         ]\n",
    "    # )\n",
    "    # .pipe(lambda s: s * df['position'])\n",
    "    # .groupby(['date', 'asset', 'direction', 'player']).max()\n",
    "    # ,\n",
    "\n",
    "    'What is the average buy/sell price?',\n",
    "    df.assign(\n",
    "        num=lambda df:\n",
    "            (df['position'] > 0).groupby(['player', 'asset']).transform(\n",
    "                lambda g: (g != g.shift()).fillna(False).cumsum().astype(int)\n",
    "            ),\n",
    "    )\n",
    "    .set_index(['num', 'direction'], append=True)\n",
    "    ['price']\n",
    "    .groupby(\n",
    "        ['player', 'asset', 'num', 'direction']\n",
    "    )\n",
    "    .agg(['min', 'max', 'mean', 'count'])\n",
    "    .dropna()\n",
    "    ,\n",
    "\n",
    "    sep='\\n{}\\n'.format('\\N{box drawings light horizontal}' * 40),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8409044a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import Series, date_range\n",
    "\n",
    "s1 = Series([1, 2, 3, 4], index=[*'aacd'])\n",
    "s2 = Series([1, 2, 3, 4], index=[*'acda'])\n",
    "\n",
    "s1 = s1.sort_index()\n",
    "s1 = s1.groupby(s1.index).mean()\n",
    "\n",
    "print(\n",
    "    # s.index.is_monotonic_increasing,\n",
    "    # s.index.has_duplicates,\n",
    "    s1 + s2,\n",
    "    sep='\\n{}\\n'.format('\\N{box drawings light horizontal}' * 40),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f617c4",
   "metadata": {},
   "source": [
    "### Question: “What is the best data service?”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed83ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Let's take a look!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07340e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from pandas import read_pickle, read_csv\n",
    "data_dir = Path('data')\n",
    "\n",
    "messages = read_pickle(data_dir / 'messages.pkl')\n",
    "\n",
    "print(\n",
    "    # messages,\n",
    "    # messages\n",
    "    # .groupby(['star', 'asset', messages.dt.to_period('H')]).min()\n",
    "    # .rename_axis(['star', 'asset', 'hour'])\n",
    "    # ,\n",
    "    # messages.to_frame().assign(\n",
    "    #     hour=lambda df: df['timestamp'].dt.to_period('H')\n",
    "    # )\n",
    "    # .set_index(['hour'], append=True)\n",
    "    # .reorder_levels(['star', 'asset', 'hour', 'service']).sort_index(),\n",
    "    (diffs := (\n",
    "        messages.to_frame().assign(\n",
    "            hour=lambda df: df['timestamp'].dt.to_period('H')\n",
    "        )\n",
    "        .set_index(['hour'], append=True)\n",
    "        .squeeze(axis='columns')\n",
    "        .reorder_levels(['star', 'asset', 'hour', 'service']).sort_index()\n",
    "        -\n",
    "        messages\n",
    "            .groupby(['star', 'asset', messages.dt.to_period('H')]).min()\n",
    "            .rename_axis(['star', 'asset', 'hour']).sort_index()\n",
    "    ))\n",
    "    .dt\n",
    "    .total_seconds()\n",
    "    .unstack('service')\n",
    "    .agg(['mean', 'std', 'min', 'max'])\n",
    "    # .astype(int)\n",
    "    # .apply(lambda s: s.minutes)\n",
    "    # .pipe(lambda s: dir(s.iloc[0]))\n",
    "    # .apply(lambda s: dir(s))\n",
    "    # .unstack('service')\n",
    "    # .rank()\n",
    "    # .var()\n",
    "    ,\n",
    "    sep='\\n{}\\n'.format('\\N{box drawings light horizontal}' * 40),\n",
    ")\n",
    "\n",
    "from matplotlib.pyplot import show, subplot_mosaic\n",
    "\n",
    "fig, axes = subplot_mosaic([\n",
    "    [svc] for svc in messages.index.get_level_values('service').unique()\n",
    "])\n",
    "\n",
    "per_service_diff = (diffs.dt.total_seconds() / 60).unstack('service')\n",
    "for svc, ax in axes.items():\n",
    "    ax.hist(\n",
    "        per_service_diff[svc],\n",
    "        bins='auto',\n",
    "        density=True, cumulative=True\n",
    "    )\n",
    "# for name in per_service_diff:\n",
    "#     col = per_service_diff[col]\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f38317d",
   "metadata": {},
   "source": [
    "## About\n",
    "\n",
    "### Don’t Use This Code; Training & Consulting\n",
    "\n",
    "Don’t Use This Code is a professional training, coaching, and consulting\n",
    "company. We are deeply invested in the open source scientific computing\n",
    "community, and are dedicated to bringing better processes, better tools, and\n",
    "better understanding to the world.\n",
    "\n",
    "**Don’t Use This Code is growing! We are currently seeking new partners, new\n",
    "clients, and new engagements for our expert consulting and training\n",
    "services.**\n",
    "\n",
    "Our ideal client is an organization, large or small, using open source\n",
    "technologies, centering around the PyData stack for scientififc and numeric\n",
    "computing. Organizations looking to better employ these tools would benefit\n",
    "from our wide range of training courses on offer, ranging from an intensive\n",
    "introduction to Python fundamentals to advanced applications of Python for\n",
    "building large-scale, production systems. Working with your team, we can craft\n",
    "targeted curricula to meet your training goals. We are also available for\n",
    "consulting services such as building scientific computing and numerical\n",
    "analysis systems using technologies like Python and React.\n",
    "\n",
    "We pride ourselves on delivering top-notch training. We are committed to\n",
    "providing quality training that is uniquely valuable to each individual\n",
    "attendee, and we do so by investing in three key areas: our\n",
    "content, our processes, and our contributors."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
